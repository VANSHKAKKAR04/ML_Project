{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2546969,"sourceType":"datasetVersion","datasetId":1544742}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:26:06.560424Z","iopub.execute_input":"2025-05-10T09:26:06.560677Z","iopub.status.idle":"2025-05-10T09:26:12.544428Z","shell.execute_reply.started":"2025-05-10T09:26:06.560652Z","shell.execute_reply":"2025-05-10T09:26:12.543463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install torch torchvision matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:17:22.225299Z","iopub.execute_input":"2025-05-30T12:17:22.225556Z","iopub.status.idle":"2025-05-30T12:18:35.144305Z","shell.execute_reply.started":"2025-05-30T12:17:22.225531Z","shell.execute_reply":"2025-05-30T12:18:35.143436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **1. Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:19:02.007528Z","iopub.execute_input":"2025-05-30T12:19:02.008121Z","iopub.status.idle":"2025-05-30T12:19:09.458720Z","shell.execute_reply.started":"2025-05-30T12:19:02.008091Z","shell.execute_reply":"2025-05-30T12:19:09.458107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **2. Load Dataset** ","metadata":{}},{"cell_type":"code","source":"# Source and destination directories\nsrc_dir = '/kaggle/input/satellite-image-classification/data'\ndst_dir = '/kaggle/working/data'\nos.makedirs(dst_dir, exist_ok=True)\n\nfor split in ['train', 'val']:\n    for cls in os.listdir(src_dir):\n        os.makedirs(os.path.join(dst_dir, split, cls), exist_ok=True)\n\n# Split and copy\nsplit_ratio = 0.8\n\nfor cls in os.listdir(src_dir):\n    imgs = os.listdir(os.path.join(src_dir, cls))\n    random.shuffle(imgs)\n\n    split_point = int(len(imgs) * split_ratio)\n    train_imgs = imgs[:split_point]\n    val_imgs = imgs[split_point:]\n\n    for img in train_imgs:\n        shutil.copy(os.path.join(src_dir, cls, img), os.path.join(dst_dir, 'train', cls, img))\n\n    for img in val_imgs:\n        shutil.copy(os.path.join(src_dir, cls, img), os.path.join(dst_dir, 'val', cls, img))\n\nprint(\"Dataset split into train/val successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:20:44.707500Z","iopub.execute_input":"2025-05-30T12:20:44.708330Z","iopub.status.idle":"2025-05-30T12:21:06.663454Z","shell.execute_reply.started":"2025-05-30T12:20:44.708305Z","shell.execute_reply":"2025-05-30T12:21:06.662686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/working/data/train'\nval_dir = '/kaggle/working/data/val'\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\n}\n\ndatasets_ = {\n    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n    'val': datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n}\n\ndataloaders = {\n    'train': DataLoader(datasets_['train'], batch_size=32, shuffle=True),\n    'val': DataLoader(datasets_['val'], batch_size=32)\n}\n\nclass_names = datasets_['train'].classes\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:22:40.824438Z","iopub.execute_input":"2025-05-30T12:22:40.824721Z","iopub.status.idle":"2025-05-30T12:22:40.938610Z","shell.execute_reply.started":"2025-05-30T12:22:40.824699Z","shell.execute_reply":"2025-05-30T12:22:40.937804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **3. Define Custom CNN**","metadata":{}},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  # 112x112\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  # 56x56\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)   # 28x28\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 28 * 28, 256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:23:11.382699Z","iopub.execute_input":"2025-05-30T12:23:11.383239Z","iopub.status.idle":"2025-05-30T12:23:11.389202Z","shell.execute_reply.started":"2025-05-30T12:23:11.383216Z","shell.execute_reply":"2025-05-30T12:23:11.388465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4. Define Train Function**","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, epochs=10):\n    for epoch in range(epochs):\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels)\n\n            epoch_loss = running_loss / len(datasets_[phase])\n            epoch_acc = running_corrects.double() / len(datasets_[phase])\n            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:26:33.597921Z","iopub.execute_input":"2025-05-30T12:26:33.598565Z","iopub.status.idle":"2025-05-30T12:26:33.604807Z","shell.execute_reply.started":"2025-05-30T12:26:33.598540Z","shell.execute_reply":"2025-05-30T12:26:33.603874Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **5. Train Custom CNN**","metadata":{}},{"cell_type":"code","source":"model_cnn = CustomCNN(num_classes=len(class_names)).to(device)\noptimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_model(model_cnn, criterion, optimizer_cnn, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:29:13.836388Z","iopub.execute_input":"2025-05-30T12:29:13.836675Z","iopub.status.idle":"2025-05-30T12:32:01.051993Z","shell.execute_reply.started":"2025-05-30T12:29:13.836655Z","shell.execute_reply":"2025-05-30T12:32:01.051344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **6. Transfer Learning (ResNet18)**","metadata":{}},{"cell_type":"code","source":"model_resnet = models.resnet18(pretrained=True)\n\n# Freeze all layers\nfor param in model_resnet.parameters():\n    param.requires_grad = False\n\n# Replace the final layer\nmodel_resnet.fc = nn.Linear(model_resnet.fc.in_features, len(class_names))\nmodel_resnet = model_resnet.to(device)\n\noptimizer_resnet = optim.Adam(model_resnet.fc.parameters(), lr=0.001)\ntrain_model(model_resnet, criterion, optimizer_resnet, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:33:41.433793Z","iopub.execute_input":"2025-05-30T12:33:41.434116Z","iopub.status.idle":"2025-05-30T12:36:29.507770Z","shell.execute_reply.started":"2025-05-30T12:33:41.434087Z","shell.execute_reply":"2025-05-30T12:36:29.507094Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **7. Evaluate Models**","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, title=\"Model\"):\n    model.eval()\n    y_true, y_pred = [], []\n\n    with torch.no_grad():\n        for inputs, labels in dataloaders['val']:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    print(f\"\\nðŸ“ˆ Classification Report for {title}:\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names,\n                yticklabels=class_names, cmap=\"Blues\")\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:36:34.765543Z","iopub.execute_input":"2025-05-30T12:36:34.766429Z","iopub.status.idle":"2025-05-30T12:36:34.772545Z","shell.execute_reply.started":"2025-05-30T12:36:34.766400Z","shell.execute_reply":"2025-05-30T12:36:34.771803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **8. Final Evaluation**","metadata":{}},{"cell_type":"code","source":"evaluate_model(model_cnn, title=\"Custom CNN\")\nevaluate_model(model_resnet, title=\"ResNet18 (Transfer Learning)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T12:39:03.475694Z","iopub.execute_input":"2025-05-30T12:39:03.476347Z","iopub.status.idle":"2025-05-30T12:39:09.584067Z","shell.execute_reply.started":"2025-05-30T12:39:03.476324Z","shell.execute_reply":"2025-05-30T12:39:09.583424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}